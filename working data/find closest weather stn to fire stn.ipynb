{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "get closest weather stations for each fire station"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   fire_id                              fire_name closest_weather_id  distance\n",
      "0      AEU            Amador - El Dorado CAL FIRE        US1CAAM0003  0.044820\n",
      "1      ANF                Angeles National Forest        USR0000CCHI  0.069613\n",
      "2      BRR  Bitter Creek National Wildlife Refuge        USC00046754  0.023635\n",
      "3      BTU                         Butte CAL FIRE        USC00046685  0.000916\n",
      "4      MCP       Camp Pendleton Marine Corps Base        USW00000369  0.027352\n",
      "..     ...                                    ...                ...       ...\n",
      "78     TCU          Tuolumne - Calaveras CAL FIRE        USC00046172  0.083267\n",
      "79     VLJ                     Vallejo Fire Dept.        USC00045333  0.045435\n",
      "80     AFV              Vandenberg Air Force Base        USW00093214  0.026880\n",
      "81     VNC                         Ventura County        US1CAVT0031  0.067191\n",
      "82     YNP                 Yosemite National Park        USC00049855  0.115259\n",
      "\n",
      "[83 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Load CSV files\n",
    "fire_stations = pd.read_csv(\"all fire stations in area_ fire.csv\")\n",
    "weather_stations = pd.read_csv(\"ghcnd-stations.csv\")\n",
    "\n",
    "def dist(x, y):\n",
    "    \"\"\"Calculate Euclidean distance between two coordinate points.\"\"\"\n",
    "    return np.sqrt((x[0] - y[0])**2 + (x[1] - y[1])**2)\n",
    "\n",
    "def find_closest(fire_stations: pd.DataFrame, weather_stations: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Find the closest weather station to each fire station.\n",
    "    \n",
    "    Parameters:\n",
    "        fire_stations (pd.DataFrame): DataFrame with columns ['fire_id', 'fire_name', 'lat', 'lon']\n",
    "        weather_stations (pd.DataFrame): DataFrame with columns ['weather_id', 'lat', 'lon']\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame with ['fire_id', 'fire_name', 'closest_weather_id', 'distance']\n",
    "    \"\"\"\n",
    "    results = []\n",
    "\n",
    "    for _, fire in fire_stations.iterrows():\n",
    "        fire_coords = (fire[\"lat\"], fire[\"lon\"])\n",
    "        min_dist = float(\"inf\")\n",
    "        closest_weather = None\n",
    "\n",
    "        for _, weather in weather_stations.iterrows():\n",
    "            weather_coords = (weather[\"lat\"], weather[\"lon\"])\n",
    "            distance = dist(fire_coords, weather_coords)\n",
    "\n",
    "            if distance < min_dist:\n",
    "                min_dist = distance\n",
    "                closest_weather = weather[\"weather_id\"]\n",
    "\n",
    "        # âœ… Fix: Correct column access using `.loc`\n",
    "        results.append([fire[\"fire_id\"], fire[\"fire_name\"], closest_weather, min_dist])\n",
    "\n",
    "    # Convert results to DataFrame\n",
    "    closest_df = pd.DataFrame(results, columns=[\"fire_id\", \"fire_name\", \"closest_weather_id\", \"distance\"])\n",
    "    return closest_df\n",
    "\n",
    "# Run function\n",
    "closest_df = find_closest(fire_stations, weather_stations)\n",
    "print(closest_df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "fireweather_conv=closest_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "fetch weather data from NOAA ftp with the list of station id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "weatherstn_list = closest_df['closest_weather_id']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "\n",
    "# Base URL\n",
    "base_url = \"https://www.ncei.noaa.gov/pub/data/ghcn/daily/by_station/\"\n",
    "\n",
    "\n",
    "\n",
    "# Directory to save downloaded files\n",
    "download_dir = \"weather_ftpfetched\"\n",
    "os.makedirs(download_dir, exist_ok=True)\n",
    "\n",
    "for station_id in weatherstn_list:\n",
    "    file_name = f\"{station_id}.csv.gz\"  # NOAA files are in .csv.gz format\n",
    "    file_url = base_url + file_name\n",
    "    local_file_path = os.path.join(download_dir, file_name)\n",
    "\n",
    "    # Download the file\n",
    "    response = requests.get(file_url, stream=True)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        with open(local_file_path, \"wb\") as file:\n",
    "            for chunk in response.iter_content(chunk_size=1024):\n",
    "                file.write(chunk)\n",
    "        print(f\"Downloaded: {file_name}\")\n",
    "    else:\n",
    "        print(f\"Failed to download: {file_name} (Status Code: {response.status_code})\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "convert csv.gz to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gzip\n",
    "import pandas as pd\n",
    "\n",
    "# Define the source folder containing .csv.gz files\n",
    "data_folder = \"weather_ftpfetched\"\n",
    "\n",
    "# Define the destination folder for converted .csv files\n",
    "converted_folder = \"weathercsv_converted\"\n",
    "\n",
    "# Create the converted folder if it doesn't exist\n",
    "os.makedirs(converted_folder, exist_ok=True)\n",
    "\n",
    "# Get a list of all .csv.gz files in the data folder\n",
    "all_files = [f for f in os.listdir(data_folder) if f.endswith('.csv.gz')]\n",
    "\n",
    "# Process each .csv.gz file\n",
    "for file in all_files:\n",
    "    input_path = os.path.join(data_folder, file)  # Full path to input file\n",
    "    output_filename = file.replace(\".csv.gz\", \".csv\")  # Change file extension\n",
    "    output_path = os.path.join(converted_folder, output_filename)  # Full path to output file\n",
    "\n",
    "    # Open the .gz file and read it using pandas\n",
    "    with gzip.open(input_path, 'rt', encoding='utf-8') as f:  # Read in text mode\n",
    "        try:\n",
    "            # Read the CSV file, skipping bad lines\n",
    "            df = pd.read_csv(f, low_memory=False, on_bad_lines='skip', sep=',')\n",
    "\n",
    "            # Print row count for debugging\n",
    "            print(f\"âœ… Read {file} with {len(df)} rows.\")\n",
    "\n",
    "            # Save the converted .csv file\n",
    "            df.to_csv(output_path, index=False)\n",
    "\n",
    "            print(f\"ðŸ“ Saved converted file to: {output_path}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"âŒ Error processing {file}: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "next step: combine all the csv into 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fixed and saved US1CAAM0003.csv\n",
      "Fixed and saved US1CACL0001.csv\n",
      "Fixed and saved US1CADN0012.csv\n",
      "Fixed and saved US1CAFR0033.csv\n",
      "Fixed and saved US1CAHM0029.csv\n",
      "Fixed and saved US1CAHM0144.csv\n",
      "Fixed and saved US1CALK0018.csv\n",
      "Fixed and saved US1CAMD0033.csv\n",
      "Fixed and saved US1CAMR0002.csv\n",
      "Fixed and saved US1CAMR0011.csv\n",
      "Fixed and saved US1CASC0006.csv\n",
      "Fixed and saved US1CASD0026.csv\n",
      "Fixed and saved US1CASK0016.csv\n",
      "Fixed and saved US1CASL0040.csv\n",
      "Fixed and saved US1CASU0005.csv\n",
      "Fixed and saved US1CASZ0043.csv\n",
      "Fixed and saved US1CAVT0017.csv\n",
      "Fixed and saved US1CAVT0031.csv\n",
      "Fixed and saved USC00040134.csv\n",
      "Fixed and saved USC00040161.csv\n",
      "Fixed and saved USC00040204.csv\n",
      "Fixed and saved USC00040332.csv\n",
      "Fixed and saved USC00040543.csv\n",
      "Fixed and saved USC00040798.csv\n",
      "Fixed and saved USC00041018.csv\n",
      "Fixed and saved USC00041075.csv\n",
      "Fixed and saved USC00041784.csv\n",
      "Fixed and saved USC00041799.csv\n",
      "Fixed and saved USC00041805.csv\n",
      "Fixed and saved USC00041906.csv\n",
      "Fixed and saved USC00042027.csv\n",
      "Fixed and saved USC00042269.csv\n",
      "Fixed and saved USC00042580.csv\n",
      "Fixed and saved USC00044176.csv\n",
      "Fixed and saved USC00044518.csv\n",
      "Fixed and saved USC00044616.csv\n",
      "Fixed and saved USC00045151.csv\n",
      "Fixed and saved USC00045212.csv\n",
      "Fixed and saved USC00045311.csv\n",
      "Fixed and saved USC00045333.csv\n",
      "Fixed and saved USC00045352.csv\n",
      "Fixed and saved USC00046136.csv\n",
      "Fixed and saved USC00046144.csv\n",
      "Fixed and saved USC00046172.csv\n",
      "Fixed and saved USC00046642.csv\n",
      "Fixed and saved USC00046685.csv\n",
      "Fixed and saved USC00046754.csv\n",
      "Fixed and saved USC00047085.csv\n",
      "Fixed and saved USC00047775.csv\n",
      "Fixed and saved USC00047950.csv\n",
      "Fixed and saved USC00048105.csv\n",
      "Fixed and saved USC00048135.csv\n",
      "Fixed and saved USC00048338.csv\n",
      "Fixed and saved USC00048702.csv\n",
      "Fixed and saved USC00049053.csv\n",
      "Fixed and saved USC00049083.csv\n",
      "Fixed and saved USC00049102.csv\n",
      "Fixed and saved USC00049600.csv\n",
      "Fixed and saved USC00049855.csv\n",
      "Fixed and saved USR0000CALD.csv\n",
      "Fixed and saved USR0000CBIH.csv\n",
      "Fixed and saved USR0000CCHI.csv\n",
      "Fixed and saved USR0000CCRE.csv\n",
      "Fixed and saved USR0000CFIG.csv\n",
      "Fixed and saved USR0000CIND.csv\n",
      "Fixed and saved USR0000CLKL.csv\n",
      "Fixed and saved USR0000CMIO.csv\n",
      "Fixed and saved USR0000CPIR.csv\n",
      "Fixed and saved USR0000CSAC.csv\n",
      "Fixed and saved USR0000CSMI.csv\n",
      "Fixed and saved USR0000CSNL.csv\n",
      "Fixed and saved USR0000CTIM.csv\n",
      "Fixed and saved USR0000CWEE.csv\n",
      "Fixed and saved USS0019L03S.csv\n",
      "Fixed and saved USW00000369.csv\n",
      "Fixed and saved USW00023248.csv\n",
      "Fixed and saved USW00053139.csv\n",
      "Fixed and saved USW00093115.csv\n",
      "Fixed and saved USW00093118.csv\n",
      "Fixed and saved USW00093205.csv\n",
      "Fixed and saved USW00093214.csv\n",
      "Fixed and saved USW00093243.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Define the folder where your CSV files are stored\n",
    "data_folder = \"weathercsv_converted\"\n",
    "\n",
    "# List all CSV files in the folder\n",
    "csv_files = [f for f in os.listdir(data_folder) if f.endswith(\".csv\")]\n",
    "\n",
    "# Define the expected columns\n",
    "expected_columns = ['id', 'date', 'obs', 'obs_value']\n",
    "\n",
    "# Iterate through all CSV files to ensure they have the same structure\n",
    "for file in csv_files:\n",
    "    file_path = os.path.join(data_folder, file)\n",
    "    \n",
    "    try:\n",
    "        # Read the current CSV file\n",
    "        df = pd.read_csv(file_path,low_memory=False)\n",
    "        \n",
    "        # Drop columns with 'Unnamed' in the name (extra columns)\n",
    "        df = df.loc[:, ~df.columns.str.contains('^Unnamed')]\n",
    "        \n",
    "        # Check if the number of columns matches the expected structure\n",
    "        if len(df.columns) >= 4:\n",
    "            # Ensure the first four columns are the expected ones\n",
    "            df = df.iloc[:, :4]  # Select the first 4 columns\n",
    "            df.columns = expected_columns  # Rename the columns\n",
    "\n",
    "            # Save the fixed CSV file\n",
    "            df.to_csv(file_path, index=False)\n",
    "            print(f\"Fixed and saved {file}\")\n",
    "        else:\n",
    "            print(f\"Skipping {file}: Not enough columns to modify.\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {file}: {e}\")\n",
    "\n",
    "# After this, all CSVs in the folder should have the same structure\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the fire dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "fire_data= pd.read_csv(r'fire_data.csv')\n",
    "fire_data= fire_data.dropna()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
